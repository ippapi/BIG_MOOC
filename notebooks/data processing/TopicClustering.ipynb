{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7954,"status":"ok","timestamp":1747034809675,"user":{"displayName":"Phương Quyên Ngô","userId":"05598022867969415322"},"user_tz":-420},"id":"Rk4P9k0FnG3C","outputId":"d8a59ada-0cc7-4321-bdfb-3ab6e2f5d9eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting spark-nlp\n","  Downloading spark_nlp-6.0.0-py2.py3-none-any.whl.metadata (19 kB)\n","Downloading spark_nlp-6.0.0-py2.py3-none-any.whl (684 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/684.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.2/684.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m684.9/684.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: spark-nlp\n","Successfully installed spark-nlp-6.0.0\n","Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n","Collecting cassandra-driver\n","  Downloading cassandra_driver-3.29.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n","Collecting geomet<0.3,>=0.1 (from cassandra-driver)\n","  Downloading geomet-0.2.1.post1-py3-none-any.whl.metadata (1.0 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from geomet<0.3,>=0.1->cassandra-driver) (8.1.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from geomet<0.3,>=0.1->cassandra-driver) (1.17.0)\n","Downloading cassandra_driver-3.29.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading geomet-0.2.1.post1-py3-none-any.whl (18 kB)\n","Installing collected packages: geomet, cassandra-driver\n","Successfully installed cassandra-driver-3.29.2 geomet-0.2.1.post1\n"]}],"source":["!pip install spark-nlp\n","!pip install pyspark cassandra-driver"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"elapsed":4762,"status":"ok","timestamp":1747034829582,"user":{"displayName":"Phương Quyên Ngô","userId":"05598022867969415322"},"user_tz":-420},"id":"ljKfy1FEnMFy","outputId":"08b03613-4bbe-41f7-b40a-1741ef4c4d1f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-b78b9931-ade3-4bc8-b0dc-3342b4063d38\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-b78b9931-ade3-4bc8-b0dc-3342b4063d38\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving secure-connect-moocassandra.zip to secure-connect-moocassandra.zip\n"]}],"source":["from google.colab import files\n","uploaded = files.upload()  # Chọn file secure-connect-bundle.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iadTnam3nOIN"},"outputs":[],"source":["import json\n","\n","with open('/content/MOOCASSANDRA-token.json') as f:\n","    secrets = json.load(f)\n","\n","CLIENT_ID = secrets[\"clientId\"]\n","CLIENT_SECRET = secrets[\"secret\"]\n","ASTRA_SECURE_BUNDLE_PATH = list(uploaded.keys())[0]\n","KEYSPACE_NAME = \"BIG_MOOC\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J1ExGdMUoFhi"},"outputs":[],"source":["from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder \\\n","    .appName(\"AstraDB-Spark-Integration\") \\\n","    .config(\"spark.driver.memory\", \"8g\") \\\n","    .config(\"spark.kryoserializer.buffer.max\", \"2000m\") \\\n","    .config(\"spark.jars.packages\",\n","            \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.5.3,com.datastax.spark:spark-cassandra-connector_2.12:3.5.1\") \\\n","    .getOrCreate()\n","\n","spark.sparkContext.addFile(ASTRA_SECURE_BUNDLE_PATH)\n","spark.conf.set(\"spark.cassandra.connection.config.cloud.path\", ASTRA_SECURE_BUNDLE_PATH)\n","spark.conf.set(\"spark.cassandra.auth.username\", CLIENT_ID)\n","spark.conf.set(\"spark.cassandra.auth.password\", CLIENT_SECRET)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3619,"status":"ok","timestamp":1746762231790,"user":{"displayName":"Phương Quyên Ngô","userId":"05598022867969415322"},"user_tz":-420},"id":"DS6DLSFEoMEg","outputId":"d805fc48-009e-4b0a-dd02-f9087ab2f2d8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Kết nối thành công! Dữ liệu mẫu:\n","+---------+-------------------------------------+--------------------+-----+---------------------------+--------------------+\n","|course_id|                                about|            about_vn|field|                       name|             name_vn|\n","+---------+-------------------------------------+--------------------+-----+---------------------------+--------------------+\n","|C_1824931|网络攻防是网络空间这个看不见硝烟的...|hành vi phạm tội ...|   []|网络安全-应用技术与工程实践|công nghệ và thực...|\n","|C_1771164|                 Causes of environ...|nguyên nhân của c...|   []|       Environmental Pol...|các sự kiện ô nhi...|\n","|C_1789680|                 Enjoy Chinese med...|thưởng thức chế đ...|   []|       A Bite of Chinese...|một miếng medica ...|\n","|C_1751256|本课程是一门硕士研究生专业基础课程...|khóa học này là m...|   []|核反应堆工程（Nuclear Re...|kỹ thuật lò phản ...|\n","| C_943258|  通过学习你可以回答下列问题：\\n如...|thông qua học tập...|   []|           物理学与世界进步|vật lý và sự tiến...|\n","+---------+-------------------------------------+--------------------+-----+---------------------------+--------------------+\n","only showing top 5 rows\n","\n","root\n"," |-- course_id: string (nullable = false)\n"," |-- about: string (nullable = true)\n"," |-- about_vn: string (nullable = true)\n"," |-- field: string (nullable = true)\n"," |-- name: string (nullable = true)\n"," |-- name_vn: string (nullable = true)\n","\n"]}],"source":["try:\n","    df = spark.read \\\n","        .format(\"org.apache.spark.sql.cassandra\") \\\n","        .options(table=\"courses\", keyspace=\"BIG_MOOC\") \\\n","        .load()\n","\n","    print(\"Kết nối thành công! Dữ liệu mẫu:\")\n","    df.show(5)\n","    df.printSchema()\n","\n","except Exception as e:\n","    print(f\"Lỗi khi kết nối: {str(e)}\")"]},{"cell_type":"markdown","metadata":{"id":"YsMVu0YwJMvt"},"source":["# TopicClustering"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SI1gvNCAoHNf"},"outputs":[],"source":["from pyspark.ml import Pipeline\n","from pyspark.ml.clustering import KMeans\n","from pyspark.ml.feature import PCA, CountVectorizer, IDF\n","from pyspark.ml.evaluation import ClusteringEvaluator\n","from pyspark.ml.feature import SQLTransformer\n","from sparknlp.base import DocumentAssembler, EmbeddingsFinisher\n","from sparknlp.annotator import XlmRoBertaSentenceEmbeddings, Tokenizer, StopWordsCleaner\n","import numpy as np\n","from pyspark.sql import Row\n","import pyspark.sql.functions as F\n","import jieba\n","import pyspark.sql.types as T\n","\n","class TopicClustering:\n","    def __init__(self, spark_session,\n","                 pca_dim=15,\n","                 random_state=42,\n","                 k_method=\"silhouette\",\n","                 min_k=2,\n","                 max_k=15):\n","        self.spark = spark_session\n","        self.pca_dim = pca_dim\n","        self.random_state = random_state\n","        self.k_method = k_method.lower()\n","        self.min_k = min_k\n","        self.max_k = max_k\n","\n","        self.embedding_model = None\n","        self.kmeans_model = None\n","        self.k = None\n","        self.transformed_df = None\n","        self.cv_model = None\n","        self.idf_model = None\n","\n","        self.evaluator = ClusteringEvaluator(\n","            featuresCol=\"pca_features\",\n","            predictionCol=\"topic\",\n","            metricName=self.k_method,\n","            distanceMeasure=\"cosine\"\n","        )\n","\n","    def _tokenize_with_jieba(self, df):\n","      stop_words = set([\n","          \"the\", \"a\", \"an\", \"of\", \"for\", \"and\", \"-\",\n","          \"on\", \"in\", \"with\", \"to\", \"at\", \"by\", \"from\", \"：\", \",\", \"!\", \"《\", \":\", \";\", \"”\", \"“\"\n","          \"（\", '）', \"·\", \"+\", \"&\", \"--\", \"?\", \"，\", \"•\", \".\", ' ', '丨', '_', '【', '】', '、', '。', '？', '；'\n","      ])\n","\n","      def jieba_tokenize(text):\n","          tokens = list(jieba.cut(text)) if text else []\n","          return [t for t in tokens if t.lower() not in stop_words and t.strip() != \"\"]\n","\n","      jieba_udf = F.udf(jieba_tokenize, T.ArrayType(T.StringType()))\n","      return df.withColumn(\"tokens_array\", jieba_udf(F.col(\"about\")))\n","\n","    def _build_embedding_pipeline(self):\n","        document_assembler = DocumentAssembler() \\\n","            .setInputCol(\"about\") \\\n","            .setOutputCol(\"document\")\n","\n","        embeddings = XlmRoBertaSentenceEmbeddings.pretrained(\"sent_xlm_roberta_base\", \"xx\") \\\n","            .setInputCols([\"document\"]) \\\n","            .setOutputCol(\"sentence_embeddings\")\n","\n","        finisher = EmbeddingsFinisher() \\\n","            .setInputCols([\"sentence_embeddings\"]) \\\n","            .setOutputCols([\"finished_embedding\"]) \\\n","            .setOutputAsVector(True) \\\n","            .setCleanAnnotations(False)\n","\n","        vector_extractor = SQLTransformer(\n","            statement=\"SELECT *, finished_embedding[0] AS embedding_vector FROM __THIS__\"\n","        )\n","\n","        pca = PCA(\n","            k=self.pca_dim,\n","            inputCol=\"embedding_vector\",\n","            outputCol=\"pca_features\"\n","        )\n","\n","        return Pipeline(stages=[\n","            document_assembler,\n","            embeddings,\n","            finisher,\n","            vector_extractor,\n","            pca\n","        ])\n","\n","    def _build_text_analysis_pipeline(self):\n","        count_vectorizer = CountVectorizer(\n","            inputCol=\"tokens_array\",\n","            outputCol=\"raw_features\"\n","        )\n","\n","        idf = IDF(\n","            inputCol=\"raw_features\",\n","            outputCol=\"features\"\n","        )\n","\n","        return Pipeline(stages=[\n","            count_vectorizer,\n","            idf\n","        ])\n","\n","    def _find_optimal_k(self, df_with_pca):\n","        scores = []\n","        models = []\n","\n","        for k in range(self.min_k, self.max_k + 1):\n","            kmeans = KMeans(\n","                k=k,\n","                seed=self.random_state,\n","                featuresCol=\"pca_features\",\n","                predictionCol=\"topic\"\n","            )\n","            model = kmeans.fit(df_with_pca)\n","            predictions = model.transform(df_with_pca)\n","            score = self.evaluator.evaluate(predictions)\n","            scores.append(score)\n","            models.append(model)\n","            print(f\"  - k={k}: {self.k_method} score = {score:.4f}\")\n","\n","        best_index = np.argmax(scores)\n","        return self.min_k + best_index, models[best_index]\n","\n","    def fit(self, df):\n","        print(\"Pipeline embedding...\")\n","        embedding_pipeline = self._build_embedding_pipeline()\n","        self.embedding_model = embedding_pipeline.fit(df)\n","        df_with_pca = self.embedding_model.transform(df).cache()\n","\n","        print(f\"Cluster: {self.min_k} to {self.max_k}...\")\n","        self.k, self.kmeans_model = self._find_optimal_k(df_with_pca)\n","        print(f\"Best k: {self.k}\")\n","\n","        clustered_df = self.kmeans_model.transform(df_with_pca).cache()\n","        df = self._tokenize_with_jieba(clustered_df)\n","\n","        print(\"TF-IDF pipeline...\")\n","        text_pipeline = self._build_text_analysis_pipeline()\n","        self.text_pipeline_model = text_pipeline.fit(df)\n","\n","        self.transformed_df = self.text_pipeline_model.transform(df).cache()\n","\n","        self.cv_model = self.text_pipeline_model.stages[0]\n","        self.idf_model = self.text_pipeline_model.stages[1]\n","\n","        df_with_pca.unpersist()\n","        clustered_df.unpersist()\n","\n","        return self\n","\n","    def transform(self, df):\n","        df_with_pca = self.embedding_model.transform(df)\n","        clustered_df = self.kmeans_model.transform(df_with_pca)\n","        df = self._tokenize_with_jieba(clustered_df)\n","        self.transformed_df = self.text_pipeline_model.transform(df).cache()\n","\n","        return self.transformed_df.select(\"course_id\", \"topic\")\n","\n","    def get_topics(self, n_words=10):\n","        vocab = self.cv_model.vocabulary\n","        idf = self.idf_model.idf.toArray()\n","        clustered_data = self.transformed_df\n","\n","        topic_words = {}\n","\n","        for topic_id in range(self.k):\n","            topic_docs = clustered_data.filter(F.col(\"topic\") == topic_id)\n","\n","            word_counts = topic_docs.select(\n","                F.explode(\"tokens_array\").alias(\"word\")\n","            ).groupBy(\"word\").count()\n","\n","            word_counts_pd = word_counts.toPandas()\n","            word_counts_pd = word_counts_pd[word_counts_pd['word'].isin(vocab)]\n","\n","            word_scores = []\n","            for _, row in word_counts_pd.iterrows():\n","                word = row['word']\n","                tf = row['count']\n","                try:\n","                    word_idx = vocab.index(word)\n","                    idf_score = idf[word_idx]\n","                    score = tf * idf_score\n","                    word_scores.append((word, score))\n","                except ValueError:\n","                    continue\n","\n","            word_scores.sort(key=lambda x: x[1], reverse=True)\n","            topic_words[topic_id] = [word for word, _ in word_scores[:n_words]]\n","\n","        return topic_words\n","\n","    def get_topic_info(self, n_words=10):\n","        clustered_data = self.transformed_df\n","        topic_keywords = self.get_topics(n_words=n_words)\n","\n","        topic_counts = (\n","            clustered_data.groupBy(\"topic\")\n","            .count()\n","            .toPandas()\n","            .set_index(\"topic\")[\"count\"]\n","            .to_dict()\n","        )\n","\n","        topic_infos = []\n","        for topic_id in sorted(topic_keywords.keys()):\n","            keywords = topic_keywords[topic_id]\n","            name = f\"{topic_id}_\" + \"_\".join(keywords)\n","            count = topic_counts.get(topic_id, 0)\n","            topic_infos.append(Row(Topic=topic_id, Count=count, Name=name))\n","\n","        return self.spark.createDataFrame(topic_infos).orderBy(\"Topic\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v0K2E8-Wscuw","executionInfo":{"status":"ok","timestamp":1746770502759,"user_tz":-420,"elapsed":5159129,"user":{"displayName":"Phương Quyên Ngô","userId":"05598022867969415322"}},"outputId":"d6a3a792-b7f8-439c-875e-7f13ba66c6dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Pipeline embedding...\n","sent_xlm_roberta_base download started this may take some time.\n","Approximate size to download 619.5 MB\n","[OK!]\n","Cluster: 100 to 150...\n","  - k=100: silhouette score = 0.1665\n","  - k=101: silhouette score = 0.1606\n","  - k=102: silhouette score = 0.1621\n","  - k=103: silhouette score = 0.1641\n","  - k=104: silhouette score = 0.1612\n","  - k=105: silhouette score = 0.1672\n","  - k=106: silhouette score = 0.1666\n","  - k=107: silhouette score = 0.1672\n","  - k=108: silhouette score = 0.1606\n","  - k=109: silhouette score = 0.1609\n","  - k=110: silhouette score = 0.1625\n","  - k=111: silhouette score = 0.1599\n","  - k=112: silhouette score = 0.1579\n","  - k=113: silhouette score = 0.1626\n","  - k=114: silhouette score = 0.1683\n","  - k=115: silhouette score = 0.1590\n","  - k=116: silhouette score = 0.1610\n","  - k=117: silhouette score = 0.1703\n","  - k=118: silhouette score = 0.1589\n","  - k=119: silhouette score = 0.1707\n","  - k=120: silhouette score = 0.1564\n","  - k=121: silhouette score = 0.1668\n","  - k=122: silhouette score = 0.1642\n","  - k=123: silhouette score = 0.1597\n","  - k=124: silhouette score = 0.1678\n","  - k=125: silhouette score = 0.1586\n","  - k=126: silhouette score = 0.1622\n","  - k=127: silhouette score = 0.1658\n","  - k=128: silhouette score = 0.1612\n","  - k=129: silhouette score = 0.1642\n","  - k=130: silhouette score = 0.1607\n","  - k=131: silhouette score = 0.1543\n","  - k=132: silhouette score = 0.1642\n","  - k=133: silhouette score = 0.1634\n","  - k=134: silhouette score = 0.1624\n","  - k=135: silhouette score = 0.1553\n","  - k=136: silhouette score = 0.1590\n","  - k=137: silhouette score = 0.1550\n","  - k=138: silhouette score = 0.1671\n","  - k=139: silhouette score = 0.1629\n","  - k=140: silhouette score = 0.1627\n","  - k=141: silhouette score = 0.1657\n","  - k=142: silhouette score = 0.1658\n","  - k=143: silhouette score = 0.1633\n","  - k=144: silhouette score = 0.1598\n","  - k=145: silhouette score = 0.1670\n","  - k=146: silhouette score = 0.1635\n","  - k=147: silhouette score = 0.1637\n","  - k=148: silhouette score = 0.1523\n","  - k=149: silhouette score = 0.1606\n","  - k=150: silhouette score = 0.1578\n","Best k: 119\n","TF-IDF pipeline...\n"]}],"source":["topicPipeline = TopicClustering(spark, min_k = 100, max_k=150)\n","topicPipeline.fit(df)\n","result_df = topicPipeline.transform(df)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":844807,"status":"ok","timestamp":1746771357410,"user":{"displayName":"Phương Quyên Ngô","userId":"05598022867969415322"},"user_tz":-420},"id":"f8kN2YyO8qby","outputId":"93fd4c83-7fe7-4c6e-9b94-663a003ca0cd"},"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+-----+---------------------------------------------------------------------------------+\n","|Topic|Count|Name                                                                             |\n","+-----+-----+---------------------------------------------------------------------------------+\n","|0    |39   |0_医学_遗传学_疾病_研究_预防_治疗_循证_诊断_临床_药物                            |\n","|1    |19   |1_is_course_students_Economics_engineering_English_basic_academic_help_compulsory|\n","|2    |14   |2_创业_总监_创新_时代_凭_互联网_知识产权_医药_创业者_人工智能                    |\n","|3    |9    |3_我们_选择_花卉_你_为什么_大学_“_音乐_可能_吗                                   |\n","|4    |51   |4_学生_计算机_和_数据库_分析_能力_软件测试_设计_学习_技术                        |\n","|5    |35   |5_工程_构造_基础_及_和_油气_的_结构_与_方程                                      |\n","|6    |27   |6_你_创业_！_创新_说法_以案_成为_一起_加入_申报                                  |\n","|7    |37   |7_俄语_摄影_你_沟通_和_学习_语言_的_也_高等数学                                  |\n","|8    |8    |8_试验_设计_神经网络_分布式_因子_人工智能_模拟_adams_专家系统_样机               |\n","|9    |17   |9_北京邮电大学_人工智能_知名_面向_名师_领域_校企_人才需求_科技人才_高层次        |\n","|10   |30   |10_is_as_you_Chinese_our_course_art_medicine_can_management                      |\n","|11   |31   |11_course_English_This_this_you_students_writing_academic_research_is            |\n","|12   |19   |12_电子_技术_数字_数据_预算_哪个_电子系统_信号处理_信息化_软件                   |\n","|13   |76   |13_周期_高校教师_全_计划_科研_提升_教学_培养_能力_蓝血京英                       |\n","|14   |1    |14_反击_抵御_威胁_身体_识别_如何_疾病_组织_并_了解                               |\n","|15   |4    |15_插花_青花瓷_哪些_人物_艺术_有_怎么_可以_青花_三点                             |\n","|16   |17   |16_历史_中国_人类_中华民族_哲学_西方_中国共产党_社会_为什么_的                   |\n","|17   |6    |17_Learn_how_What_organize_resists_counterattacks_threats_city_identify_here     |\n","|18   |28   |18_实验_统计_爆炸_中_模型_多元_的_都_流体力学_到                                 |\n","|19   |11   |19_师德_心理_教育_心理健康_发展_大学生_意识_（_教师_孩子                         |\n","|20   |46   |20_文化_中国_对_艺术_的_民族_儿童_电影_中_审美                                   |\n","|21   |40   |21_企业_管理_并购_运营_营销_物流_品牌_重组_驱动_人力                             |\n","|22   |1    |22_clinical_patients_examination_physical_diagnosis_how_A2_lab_concerns_Q2       |\n","|23   |29   |23_动作_妊娠_运动_学生_排球_交流_学习_婴儿_的_及                                 |\n","|24   |23   |24_葡萄酒_你_如果_会展_！_谈判_估值_之_学_想                                     |\n","|25   |28   |25_你_世界_物理_有机化学_！_轮滑_您_一起_的_将                                   |\n","|26   |8    |26_礼仪_体育_安全_谁_武术_教学_吗_—_体教_风险                                    |\n","|27   |7    |27_三江_旅顺口_海拔_源_生态_爱国主义_无_地区_“_文化                              |\n","|28   |56   |28_专业_学生_国际_课程_体育_是_为_的_研究生_培养                                 |\n","|29   |30   |29_文化_之美_中国_冬奥_昆曲_我们_经典_艺术_插花_服饰                             |\n","|30   |34   |30_创业_广告创意_时尚_企业_广告_战略_“_微软_管理_服务                            |\n","|31   |24   |31_失败_房地产_女装_投资_设计_发展_互联网_时尚_女性_时装                         |\n","|32   |10   |32_经济学_很_什么_思想_太阳能_你_模块_会计_想_政治                               |\n","|33   |53   |33_化学_学生_专业_课程_是_原理_的_基础_为_一门                                   |\n","|34   |19   |34_管理_数据_理论_机器_思维_方法_学习_经济学_是_马克思主义                       |\n","|35   |72   |35_创业_管理_公共_能力_学生_创新_专业_数据_工作_的                               |\n","|36   |39   |36_游戏_设计_制作_模型_区_托育_软件_的_汽车_动作                                 |\n","|37   |45   |37_工程_专业_设计_工艺_技术_是_原理_和_机械_的                                   |\n","|38   |30   |38_is_technology_you_gas_has_\"_their_energy_clinical_one                         |\n","|39   |46   |39_经济_发展_核_生活_的_人类_环境_和_你_中                                       |\n","|40   |20   |40_物理_你_！_大_想_我们_结识_侦探_成为_大师                                     |\n","|41   |25   |41_艺术_写作_我们_是_哲学_你_生活_精神_根本_美                                   |\n","|42   |31   |42_学生_设计_化妆_第二语言_学习_能力_摄影_艺术_表现_视觉                         |\n","|43   |22   |43_市场营销_老年学_系统工程_医药_疫情_健康_…_法医_物证_“                         |\n","|44   |18   |44_随机_代数_矩阵_数学_线性代数_几何_级数_模型_函数_概率                         |\n","|45   |2    |45_安全_大学生_火灾事故_法制观念_消防安全_防范_总体_较强_体现_发生               |\n","|46   |19   |46_戏剧_你_只是_广告创意_韬略_如何_马克思主义_社会主义_系统工程_怎么             |\n","|47   |8    |47_专题_这是_地球_！_战争_最_怎么_蓝色_吗_家园                                   |\n","|48   |26   |48_燃烧_流体_运动_研究_土壤_地理学_化学_力学_结构_生态系统                       |\n","|49   |4    |49_爱情_指_密码_美学_创业_4_3_之谜_7_“                                           |\n","|50   |43   |50_“_配送_小_程序_作业_中心_备赛_专业_开发_微信                                  |\n","|51   |7    |51_piano_Chinese_art_is_This_course_hotel_scenes_same_basic                      |\n","|52   |23   |52_酒水_舞蹈_教学_英语_儿童_考评_\"_学习_考核_相结合                              |\n","|53   |49   |53_学生_技术_的_方法_设计_和_专业_对_系统_应用                                   |\n","|54   |39   |54_治理_项目_讲座_由_在线_信息安全_人工智能_AI_学堂_组成                         |\n","|55   |18   |55_沟通_SCI_中医_你_论文_吗_翻译_写作_把_力                                      |\n","|56   |14   |56_插花_/_花店_分析法_信号处理_DSP_花艺师_艺术_你_学习                           |\n","|57   |9    |57_物流_训练_会计_Any_生产_~_章_什么样_模块_什么                                 |\n","|58   |22   |58_服装_摄影_你_我们_您_设计师_如果_云南_有_文化                                 |\n","|59   |17   |59_设计_样板_人像_推板_广告_服装_美学_摄影_多媒体_与                             |\n","|60   |10   |60_灾害_健康_信息_传播_葡萄酒_体育运动_运动_汽车_与_影响                         |\n","|61   |17   |61_土地_政府_通信_是_强国_网络_贸易_俄罗斯_感染_能源                             |\n","|62   |48   |62_数学_力学_讲_问题_学生_和_随机_方法_实际_线性代数                             |\n","|63   |37   |63_中国_文化_发展_舞蹈_传播_旅游_电影_与_本_历史                                 |\n","|64   |24   |64_应急_中国_事件_视角_环境_民法_犯罪_归因_外交_史记                             |\n","|65   |30   |65_护理_城市_理论_研究_临床_工作_课程内容_以_为_和                               |\n","|66   |1    |66_sing_gestures_sentence_opera_tone_suddenly_One_back_story_expressions         |\n","|67   |3    |67_food_营销_is_everybody_you_me_called_course_This_this                         |\n","|68   |12   |68_酒店_英语_你_吗_—_想_！_觉得_日本_文化                                        |\n","|69   |33   |69_设计_工程_高分子_导航_方法_受力_是_结构_和_等                                 |\n","|70   |14   |70_数学_吗_世界_化学_演化_第_时_(_你_规律                                        |\n","|71   |18   |71_应用_编译器_设计_C语言_IC_嵌入式_界面设计_为_编译_（                          |\n","|72   |18   |72_英语_写作_演讲_韩语_语法_学生_辩论_英文_学习者_思辨                           |\n","|73   |2    |73_押题_串讲_考前_应试_预测_技巧_四级_六级                                       |\n","|74   |22   |74_丝路_南线_云南_民间工艺_终南_文化_“_昆虫_上_…                                 |\n","|75   |25   |75_设计_有_艺术_审美_幼儿_什么_明代_的_感受_文化                                 |\n","|76   |9    |76_course_English_better_)_(_teaching_molecules_Mandarin_explores_varied         |\n","|77   |10   |77_双创_—_人工智能_当_公司_了_person_software_组建_真的                          |\n","|78   |17   |78_创业_图案_你_如何_吗_时尚_商业_行业_“_想                                      |\n","|79   |36   |79_健康_医学_疾病_临床_人体_分子_治疗_与_解剖学_常见                             |\n","|80   |33   |80_course_is_you_will_this_as_This_basic_students_Erhu                           |\n","|81   |9    |81_Web_攻击_技术_国际_服务器_针对_工程_（_3_信息安全                             |\n","|82   |26   |82_投资_数据库_财务报表_智能_装配式_机器人_数据_证券_实现_网络                   |\n","|83   |23   |83_you_course_Why_is_will_Chinese_are_\"_animal_fish                              |\n","|84   |16   |84_艺术品_定性_思维_问题_社会_是_建筑_历史_和_绿色                               |\n","|85   |45   |85_年_清华大学_研究生_在线_答辩_STEM_飞行_月_发布_于                             |\n","|86   |26   |86_女性_健康_性_“_户外_兵棋_调理_医患_吗_常见                                    |\n","|87   |28   |87_力学_科学_马克思主义_生物_技术_传感器_复合材料_研究_“_物理                    |\n","|88   |14   |88_全额_疾风_限额_专属_内功_首期_招募_名校_奖励_2021                             |\n","|89   |44   |89_course_design_is_you_this_methods_different_This_It_can                       |\n","|90   |6    |90_China_heat_phenomenon_thermal_law_We_dvelopment_tax_taxpayer_understand       |\n","|91   |23   |91_股权_馆_亲子_你_融资_油_！_想_吗_服装                                         |\n","|92   |32   |92_建筑_技术_与_数据_java_应用_和_模型_工程_学生                                 |\n","|93   |20   |93_健康_疾病_你_吗_是否_我们_！_电_食品_如何                                     |\n","|94   |43   |94_专业_基础_英语_学生_是_学术_课程_学习_的_能力                                 |\n","|95   |28   |95_技术_领域_EDA_电子_电工_城市_您_电子政务_工程_新                              |\n","|96   |23   |96_婴幼儿_安全_牧草_如何_纺织品_种子_植物_我们_服装_家庭                         |\n","|97   |16   |97_创新_创业_大学生_积极_法治_心理学_成长_价值观_设计_能力                       |\n","|98   |19   |98_心理学_设计_医学_智能_✍_以_信息技术_与_为_导向                                |\n","|99   |30   |99_AWS_Amazon_云_服务_客户_技术_应用_得_了_网站                                  |\n","|100  |14   |100_you_course_be_our_This_TCM_it_is_Hospitality_world                           |\n","|101  |31   |101_网球_！_我们_寄生虫_人_运动_文化_“_的_植物                                   |\n","|102  |14   |102_（_上海_教材_教学研究_发表_逻辑_)_(_评估_广东省                              |\n","|103  |29   |103_英语_汉语_笔译_手语_语法_语言_学生_词汇_日语_语言学                          |\n","|104  |20   |104_血瘀_香农_马克思主义_信息论_当代_21_考研_培训_人体_寄生虫                    |\n","|105  |3    |105_design_)_(_x_contemporary_experiment_CS_electronic_systematically_as         |\n","|106  |17   |106_你_吗_语音_想_还_会计_英语_不_而_在                                          |\n","|107  |13   |107_行政_教学_社会_道德修养_职_思想_如何_大学_岗位职责_升职                      |\n","|108  |6    |108_如何_劳动合同_知道_你_应该_吗_离职_职场_求职_劳动                            |\n","|109  |6    |109_Chinese_customs_you_people_traditional_art_paintings_IWP_which_slightly      |\n","|110  |23   |110_想_吗_你_机器人_知道_包装材料_雷达_反应器_信号_会计                          |\n","|111  |29   |111_海洋_供热_你_森林_了_吗_复合材料_想_如何_我们                                |\n","|112  |21   |112_Chinese_culture_is_world_\"_life_medicine_traditional_us_editing              |\n","|113  |28   |113_course_is_engineering_pharmacology_students_teaching_ability_'_This_skills   |\n","|114  |17   |114_tourism_development_you_intelligence_course_China_this_since_’_its           |\n","|115  |62   |115_工程_专业_设计_和_技术_与_是_的_学生_基础                                    |\n","|116  |11   |116_打印_传动_电工_3D_液压_程序设计_电子_智能_芯片_C语言                         |\n","|117  |27   |117_中国_文化_历史_以_文学_德国_音乐_为_精神_藏文                                |\n","|118  |32   |118_输血_区域_护理_检验_康复_水声_医学_游泳_药理_专业                            |\n","+-----+-----+---------------------------------------------------------------------------------+\n","\n"]}],"source":["topicPipeline.get_topic_info().show(n=150, truncate=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F1JkeuLwxJN4","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1746771367980,"user_tz":-420,"elapsed":1790,"user":{"displayName":"Phương Quyên Ngô","userId":"05598022867969415322"}},"outputId":"7a3ab911-3836-42b8-b51f-7fbbe59ebdc8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/result.txt'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}],"source":["import shutil\n","import glob\n","import os\n","\n","# Coalesce để gộp về 1 partition\n","result_df.coalesce(1).rdd \\\n","    .map(lambda row: \"\\t\".join([str(c) for c in row])) \\\n","    .saveAsTextFile(\"/content/result_txt\")\n","part_file = glob.glob(\"/content/result_txt/part-*\")[0]\n","shutil.move(part_file, \"/content/result.txt\")"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMU9XwC4PnyctDvkOQ4dmGS"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}